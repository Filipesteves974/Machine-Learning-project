{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354ff4a-dd23-4fa4-a6aa-21fa65fb9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x):\n",
    "    x = str(x)\n",
    "    x = x.lower()\n",
    "    x = x.replace(\"_\", \"\")\n",
    "    x = x.replace(\"-\", \"\")\n",
    "    x = x.replace(\" \", \"\")\n",
    "    if x == \"nan\":\n",
    "        return np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5d102-846f-4b46-865d-31809677b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_missing_letters(value, valid_list, max_missing=2):\n",
    "    \"\"\"\n",
    "    corrects values with missing letters based on valid_list\n",
    "    \"\"\"\n",
    "    best_match = value\n",
    "    smallest_diff = 999\n",
    "    if pd.isna(value):  # <- ignores NaN\n",
    "        return np.nan\n",
    "    for ref in valid_list:\n",
    "        # absolute length difference\n",
    "        len_diff = abs(len(ref) - len(value))\n",
    "        if len_diff == 0 or len_diff > max_missing:\n",
    "            continue  # ignora se igual ou diferença > limite\n",
    "\n",
    "        # verificar se o valor é subsequência do nome correto (mantendo ordem)\n",
    "        it = iter(ref)\n",
    "        is_subseq = all(ch in it for ch in value)\n",
    "\n",
    "        if is_subseq and len_diff < smallest_diff:\n",
    "            smallest_diff = len_diff\n",
    "            best_match = ref\n",
    "\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2572c-d25a-4c4b-bb0e-2a5d232f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_smart_v2(X_train, X_val, y_train, y_val):\n",
    "\n",
    "    X_tr = X_train.copy()\n",
    "    X_v = X_val.copy()\n",
    "    y_tr = y_train.copy()\n",
    "    y_v = y_val.copy()\n",
    "    \n",
    "    \n",
    "    if 'year' in X_tr.columns:\n",
    "        mask_tr = X_tr['year'] >= 1990\n",
    "        mask_v = X_v['year'] >= 1990\n",
    "        removed_tr = (~mask_tr).sum()\n",
    "        removed_v = (~mask_v).sum()\n",
    "        if removed_tr > 0 or removed_v > 0:\n",
    "            print(f\"\\n[YEAR < 1990]\")\n",
    "            print(f\" {removed_tr} train, {removed_v} val\")\n",
    "        X_tr, y_tr = X_tr[mask_tr], y_tr[mask_tr]\n",
    "        X_v, y_v = X_v[mask_v], y_v[mask_v]\n",
    "    \n",
    "\n",
    "    print(f\"\\n[PRICE - Target]\")\n",
    "\n",
    "    mask_tr = y_tr >= 1000\n",
    "    mask_v = y_v >= 1000\n",
    "    print(f\" Price < £1000: {(~mask_tr).sum()} train, {(~mask_v).sum()} val\")\n",
    "    X_tr, y_tr = X_tr[mask_tr], y_tr[mask_tr]\n",
    "    X_v, y_v = X_v[mask_v], y_v[mask_v]\n",
    "    \n",
    "    \n",
    "    upper_price = y_train.quantile(0.995)\n",
    "    mask_tr = y_tr <= upper_price\n",
    "    mask_v = y_v <= upper_price\n",
    "    print(f\" Price > £{upper_price:,.0f} (P99.5): {(~mask_tr).sum()} train, {(~mask_v).sum()} val\")\n",
    "    X_tr, y_tr = X_tr[mask_tr], y_tr[mask_tr]\n",
    "    X_v, y_v = X_v[mask_v], y_v[mask_v]\n",
    "    \n",
    "\n",
    "    \n",
    "    if 'mileage' in X_tr.columns:\n",
    "        print(f\"\\n[MILEAGE]\")\n",
    "        \n",
    "        upper_mileage = X_train['mileage'].quantile(0.99)\n",
    "        train_above = (X_tr['mileage'] > upper_mileage).sum()\n",
    "        val_above = (X_v['mileage'] > upper_mileage).sum()\n",
    "        print(f\" P99 = {upper_mileage:,.0f} milhas\")\n",
    "        print(f\" Capped: {train_above} train, {val_above} val\")\n",
    "        X_tr['mileage'] = np.clip(X_tr['mileage'], 0, upper_mileage)\n",
    "        X_v['mileage'] = np.clip(X_v['mileage'], 0, upper_mileage)\n",
    "    \n",
    "\n",
    "    if 'mpg' in X_tr.columns:\n",
    "        print(f\"\\n[MPG]\")\n",
    "        # MPG muito alto (>80) é raro em carros usados normais\n",
    "        q_low = X_tr['mpg'].quantile(0.005)  # Mais agressivo: 0.5% em vez de 1%\n",
    "        q_high = X_tr['mpg'].quantile(0.98)  # 98% em vez de 99%\n",
    "        print(f\" [{q_low:.1f}, {q_high:.1f}] MPG (0.5%–98%)\")\n",
    "        \n",
    "        train_affected = ((X_tr['mpg'] < q_low) | (X_tr['mpg'] > q_high)).sum()\n",
    "        val_affected = ((X_v['mpg'] < q_low) | (X_v['mpg'] > q_high)).sum()\n",
    "        print(f\"  {train_affected} train, {val_affected} val\")\n",
    "        \n",
    "        X_tr['mpg'] = np.clip(X_tr['mpg'], q_low, q_high)\n",
    "        X_v['mpg'] = np.clip(X_v['mpg'], q_low, q_high)\n",
    "    \n",
    "\n",
    "    if 'tax' in X_tr.columns:\n",
    "        print(f\"\\n[TAX]\")\n",
    "        upper_tax = X_train['tax'].quantile(0.98)\n",
    "        train_above = (X_tr['tax'] > upper_tax).sum()\n",
    "        val_above = (X_v['tax'] > upper_tax).sum()\n",
    "        print(f\"  P98 = £{upper_tax:.0f}\")\n",
    "        print(f\"  Capped: {train_above} train, {val_above} val\")\n",
    "        X_tr['tax'] = np.clip(X_tr['tax'], 0, upper_tax)\n",
    "        X_v['tax'] = np.clip(X_v['tax'], 0, upper_tax)\n",
    "    \n",
    "\n",
    "    if 'engineSize' in X_tr.columns:\n",
    "        print(f\"\\n[ENGINE SIZE]\")\n",
    "        \n",
    "        mask_tr = X_tr['engineSize'] <= 6.0\n",
    "        mask_v = X_v['engineSize'] <= 6.0\n",
    "        removed_tr = (~mask_tr).sum()\n",
    "        removed_v = (~mask_v).sum()\n",
    "        if removed_tr > 0 or removed_v > 0:\n",
    "            print(f\" Engine > 6.0L: {removed_tr} train, {removed_v} val\")\n",
    "        X_tr, y_tr = X_tr[mask_tr], y_tr[mask_tr]\n",
    "        X_v, y_v = X_v[mask_v], y_v[mask_v]\n",
    "    \n",
    "\n",
    "    print(f\"\\n[Logic Validation]\")\n",
    "    \n",
    "    \n",
    "    if 'year' in X_tr.columns and 'mileage' in X_tr.columns:\n",
    "        current_year = 2025  \n",
    "        mask_tr = ~((current_year - X_tr['year'] <= 3) & (X_tr['mileage'] > 100000))\n",
    "        mask_v = ~((current_year - X_v['year'] <= 3) & (X_v['mileage'] > 100000))\n",
    "        removed_tr = (~mask_tr).sum()\n",
    "        removed_v = (~mask_v).sum()\n",
    "        if removed_tr > 0 or removed_v > 0:\n",
    "            print(f\"  {removed_tr} train, {removed_v} val\")\n",
    "        X_tr, y_tr = X_tr[mask_tr], y_tr[mask_tr]\n",
    "        X_v, y_v = X_v[mask_v], y_v[mask_v]\n",
    "    \n",
    " \n",
    "    if 'mpg' in X_tr.columns and 'engineSize' in X_tr.columns:\n",
    "        mask_tr = ~((X_tr['engineSize'] > 4.0) & (X_tr['mpg'] > 60))\n",
    "        mask_v = ~((X_v['engineSize'] > 4.0) & (X_v['mpg'] > 60))\n",
    "        removed_tr = (~mask_tr).sum()\n",
    "        removed_v = (~mask_v).sum()\n",
    "        if removed_tr > 0 or removed_v > 0:\n",
    "            print(f\": {removed_tr} train, {removed_v} val\")\n",
    "        X_tr, y_tr = X_tr[mask_tr], y_tr[mask_tr]\n",
    "        X_v, y_v = X_v[mask_v], y_v[mask_v]\n",
    "    \n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Final: {len(X_tr)} train ({100*len(X_tr)/len(X_train):.1f}%), \"\n",
    "          f\"{len(X_v)} val ({100*len(X_v)/len(X_val):.1f}%)\")\n",
    "    print(f\"Removed: {len(X_train) - len(X_tr)} train ({100*(len(X_train)-len(X_tr))/len(X_train):.2f}%), \"\n",
    "          f\"{len(X_val) - len(X_v)} val ({100*(len(X_val)-len(X_v))/len(X_val):.2f}%)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return X_tr, X_v, y_tr, y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed159bc-186b-488b-8cbc-d53b2a45214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values_hybrid(X_train, X_val, X_test, create_flags=True):\n",
    "    \"\"\"\n",
    "    Hybrid intelligent imputation:\n",
    "    1. Simple categorical: model, Brand (rules + mode)\n",
    "    2. Conditional categorical: fuelType, transmission (mode by group)\n",
    "    3. Binary flags: has_damage, has_reported_damage (mode)\n",
    "    4. Correlated numerical: IterativeImputer (MICE)\n",
    "    5. Optional flags to indicate imputed values\n",
    "    \"\"\"\n",
    "    X_tr = X_train.copy()\n",
    "    X_v = X_val.copy()\n",
    "    X_te = X_test.copy()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"HYBRID IMPUTATION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 0: Create missing flags (BEFORE imputation)\n",
    "    # =========================================================================\n",
    "    if create_flags:\n",
    "        print(\"\\n[CREATING MISSING FLAGS]\")\n",
    "        cols_to_flag = ['model', 'Brand', 'year', 'engineSize', 'mileage', \n",
    "                        'fuelType', 'transmission', 'mpg', 'tax', 'previousOwners',\n",
    "                        'has_damage', 'has_reported_damage']\n",
    "        \n",
    "        if 'paintQuality%' in X_tr.columns:\n",
    "            cols_to_flag.append('paintQuality%')\n",
    "        \n",
    "        for col in cols_to_flag:\n",
    "            if col in X_tr.columns:\n",
    "                X_tr[f'{col}_was_missing'] = X_tr[col].isna().astype(int)\n",
    "                X_v[f'{col}_was_missing'] = X_v[col].isna().astype(int)\n",
    "                X_te[f'{col}_was_missing'] = X_te[col].isna().astype(int)\n",
    "        \n",
    "        print(f\"  Created {len([c for c in cols_to_flag if c in X_tr.columns])} missing flags\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 1: MODEL (global mode)\n",
    "    # =========================================================================\n",
    "    print(\"\\n[1/6] MODEL - global mode\")\n",
    "    \n",
    "    global_mode_model = X_tr[\"model\"].mode()[0] if len(X_tr[\"model\"].mode()) > 0 else \"unknown\"\n",
    "    \n",
    "    n_missing_train = X_tr[\"model\"].isna().sum()\n",
    "    X_tr[\"model\"].fillna(global_mode_model, inplace=True)\n",
    "    X_v[\"model\"].fillna(global_mode_model, inplace=True)\n",
    "    X_te[\"model\"].fillna(global_mode_model, inplace=True)\n",
    "    \n",
    "    print(f\"  Global mode: '{global_mode_model}'\")\n",
    "    print(f\"  Imputed - Train: {n_missing_train}, Val: {X_val['model'].isna().sum()}, \"\n",
    "          f\"Test: {X_test['model'].isna().sum()}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 2: BRAND (inferred from model, then mode)\n",
    "    # =========================================================================\n",
    "    print(\"\\n[2/6] BRAND - inferred from model + learned mapping\")\n",
    "    \n",
    "    # Create model->Brand dictionary from known data\n",
    "    model_to_brand_map = (\n",
    "        X_tr.dropna(subset=['Brand', 'model'])\n",
    "        .groupby('model')['Brand']\n",
    "        .agg(lambda x: x.mode()[0] if len(x.mode()) > 0 else None)\n",
    "        .to_dict()\n",
    "    )\n",
    "    \n",
    "    # Fallback: hardcoded lists for cases not in data\n",
    "    toyota = [\"yaris\", \"aygo\", \"corolla\", \"chr\", \"avensis\", \"prius\", \"rav4\", \"hilux\", \n",
    "              \"verso\", \"supra\", \"landcruiser\", \"camry\", \"proaceverso\", \"urbancruiser\", \n",
    "              \"auris\", \"gt86\"]\n",
    "    ford = [\"focus\", \"fiesta\", \"mondeo\", \"kuga\", \"galaxy\", \"smax\", \"bmax\", \"ecosport\", \n",
    "            \"puma\", \"tourneocustom\", \"tourneoconnect\", \"grandtourneoconnect\", \"cmax\", \n",
    "            \"grandcmax\", \"edge\", \"mustang\", \"fusion\", \"streetka\", \"ranger\", \"escort\", \n",
    "            \"ka\", \"ka+\"]\n",
    "    opel = [\"corsa\", \"mokkax\", \"astra\", \"insignia\", \"mokka\", \"zafira\", \"viva\", \"meriva\", \n",
    "            \"adam\", \"combolife\", \"crosslandx\", \"grandlandx\", \"gtc\", \"antara\", \"vivaro\", \n",
    "            \"vectra\", \"agila\", \"tigra\", \"cascada\", \"ampera\"]\n",
    "    vw = [\"golf\", \"golfsv\", \"polo\", \"passat\", \"tiguan\", \"tiguanallspace\", \"touran\", \n",
    "          \"touareg\", \"troc\", \"tcross\", \"arteon\", \"sharan\", \"jetta\", \"cc\", \"caravelle\", \n",
    "          \"california\", \"caddy\", \"caddymaxi\", \"beetle\", \"scirocco\", \"up\", \"amarok\", \"eos\", \"fox\"]\n",
    "    audi = [\"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\", \"a7\", \"a8\", \"q2\", \"q3\", \"q5\", \"q7\", \n",
    "            \"q8\", \"s3\", \"s4\", \"s5\", \"s8\", \"rs3\", \"rs4\", \"rs5\", \"rs6\", \"sq5\", \"sq7\", \"tt\", \"r8\"]\n",
    "    mercedes = [\"aclass\", \"bclass\", \"cclass\", \"eclass\", \"sclass\", \"claclass\", \"clsclass\", \n",
    "                \"glaclass\", \"glbclass\", \"glcclass\", \"gleclass\", \"glsclass\", \"glclass\", \n",
    "                \"gclass\", \"vclass\", \"xclass\", \"slclass\", \"slkclass\", \"mclass\", \"slc\", \n",
    "                \"clk\", \"clclass\", \"clcclass\", \"mercedes200\", \"mercedes220\", \"mercedes230\"]\n",
    "    skoda = [\"fabia\", \"octavia\", \"superb\", \"karoq\", \"kodiaq\", \"kamiq\", \"yeti\", \n",
    "             \"yetioutdoor\", \"scala\", \"rapid\", \"citigo\", \"roomster\"]\n",
    "    hyundai = [\"i10\", \"i20\", \"i30\", \"i40\", \"i800\", \"ioniq\", \"kona\", \"tucson\", \"santafe\", \n",
    "               \"getz\", \"ix20\", \"ix35\", \"veloster\", \"accent\", \"terracan\"]\n",
    "    bmw_models = [\"series1\", \"series2\", \"series3\", \"series4\", \"series5\", \"series6\", \n",
    "                  \"series7\", \"series8\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \n",
    "                  \"z3\", \"z4\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\", \"iq\"]\n",
    "    seat_models = [\"leon\", \"ateca\", \"toledo\", \"arona\", \"ibiza\", \"alhambra\"]\n",
    "    \n",
    "    def infer_brand_smart(model_val):\n",
    "        if pd.isna(model_val):\n",
    "            return None\n",
    "        \n",
    "        # First try learned mapping\n",
    "        if model_val in model_to_brand_map:\n",
    "            return model_to_brand_map[model_val]\n",
    "        \n",
    "        # Fallback to hardcoded lists\n",
    "        m = str(model_val).lower()\n",
    "        if m in toyota: return \"toyota\"\n",
    "        if m in ford: return \"ford\"\n",
    "        if m in opel: return \"opel\"\n",
    "        if m in vw: return \"vw\"\n",
    "        if m in audi: return \"audi\"\n",
    "        if m in bmw_models: return \"bmw\"\n",
    "        if m in mercedes: return \"mercedes\"\n",
    "        if m in skoda: return \"skoda\"\n",
    "        if m in hyundai: return \"hyundai\"\n",
    "        if m in seat_models: return \"seat\"\n",
    "        if m == \"kadjar\": return \"renault\"\n",
    "        if m == \"shuttle\": return \"honda\"\n",
    "        return None\n",
    "    \n",
    "    # Apply inference\n",
    "    n_missing_brand = X_tr[\"Brand\"].isna().sum()\n",
    "    for df in [X_tr, X_v, X_te]:\n",
    "        mask_nan = df[\"Brand\"].isna()\n",
    "        df.loc[mask_nan, \"Brand\"] = df.loc[mask_nan, \"model\"].apply(infer_brand_smart)\n",
    "    \n",
    "    # Global mode for remaining\n",
    "    global_mode_brand = X_tr[\"Brand\"].mode()[0] if len(X_tr[\"Brand\"].mode()) > 0 else \"ford\"\n",
    "    X_tr[\"Brand\"].fillna(global_mode_brand, inplace=True)\n",
    "    X_v[\"Brand\"].fillna(global_mode_brand, inplace=True)\n",
    "    X_te[\"Brand\"].fillna(global_mode_brand, inplace=True)\n",
    "    \n",
    "    print(f\"  Learned mapping: {len(model_to_brand_map)} models\")\n",
    "    print(f\"  Imputed - Train: {n_missing_brand}, Val: {X_val['Brand'].isna().sum()}, \"\n",
    "          f\"Test: {X_test['Brand'].isna().sum()}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 3: CONDITIONAL CATEGORICAL (fuelType, transmission)\n",
    "    # =========================================================================\n",
    "    print(\"\\n[3/6] FUELTYPE & TRANSMISSION - mode by group\")\n",
    "    \n",
    "    # fuelType by Brand\n",
    "    mode_fueltype_brand = (\n",
    "        X_tr.groupby(\"Brand\")[\"fuelType\"]\n",
    "        .apply(lambda x: x.mode()[0] if len(x.mode()) > 0 else np.nan)\n",
    "    )\n",
    "    global_mode_fueltype = X_tr[\"fuelType\"].mode()[0] if len(X_tr[\"fuelType\"].mode()) > 0 else \"Petrol\"\n",
    "    \n",
    "    def fill_fueltype(row):\n",
    "        if pd.notna(row[\"fuelType\"]):\n",
    "            return row[\"fuelType\"]\n",
    "        val = mode_fueltype_brand.get(row[\"Brand\"], global_mode_fueltype)\n",
    "        return val if pd.notna(val) else global_mode_fueltype\n",
    "    \n",
    "    n_missing_fuel = X_tr[\"fuelType\"].isna().sum()\n",
    "    X_tr[\"fuelType\"] = X_tr.apply(fill_fueltype, axis=1)\n",
    "    X_v[\"fuelType\"] = X_v.apply(fill_fueltype, axis=1)\n",
    "    X_te[\"fuelType\"] = X_te.apply(fill_fueltype, axis=1)\n",
    "    \n",
    "    # transmission by Brand + fuelType\n",
    "    mode_transmission_brandfuel = (\n",
    "        X_tr.groupby([\"Brand\", \"fuelType\"])[\"transmission\"]\n",
    "        .apply(lambda x: x.mode()[0] if len(x.mode()) > 0 else np.nan)\n",
    "    )\n",
    "    mode_transmission_brand = (\n",
    "        X_tr.groupby(\"Brand\")[\"transmission\"]\n",
    "        .apply(lambda x: x.mode()[0] if len(x.mode()) > 0 else np.nan)\n",
    "    )\n",
    "    global_mode_transmission = X_tr[\"transmission\"].mode()[0] if len(X_tr[\"transmission\"].mode()) > 0 else \"Manual\"\n",
    "    \n",
    "    def fill_transmission(row):\n",
    "        if pd.notna(row[\"transmission\"]):\n",
    "            return row[\"transmission\"]\n",
    "        val = mode_transmission_brandfuel.get((row[\"Brand\"], row[\"fuelType\"]))\n",
    "        if pd.isna(val):\n",
    "            val = mode_transmission_brand.get(row[\"Brand\"], global_mode_transmission)\n",
    "        return val if pd.notna(val) else global_mode_transmission\n",
    "    \n",
    "    n_missing_trans = X_tr[\"transmission\"].isna().sum()\n",
    "    X_tr[\"transmission\"] = X_tr.apply(fill_transmission, axis=1)\n",
    "    X_v[\"transmission\"] = X_v.apply(fill_transmission, axis=1)\n",
    "    X_te[\"transmission\"] = X_te.apply(fill_transmission, axis=1)\n",
    "    \n",
    "    print(f\"  fuelType imputed - Train: {n_missing_fuel}\")\n",
    "    print(f\"  transmission imputed - Train: {n_missing_trans}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 3.5: BINARY FLAGS (has_damage, has_reported_damage)\n",
    "    # =========================================================================\n",
    "    print(\"\\n[3.5/6] BINARY FLAGS - has_damage, has_reported_damage\")\n",
    "    \n",
    "    for col in ['has_damage', 'has_reported_damage']:\n",
    "        if col in X_tr.columns:\n",
    "            mode_val = X_tr[col].mode()[0] if len(X_tr[col].mode()) > 0 else 0\n",
    "            n_missing_train = X_tr[col].isna().sum()\n",
    "            n_missing_val = X_v[col].isna().sum()\n",
    "            n_missing_test = X_te[col].isna().sum()\n",
    "            \n",
    "            X_tr[col].fillna(mode_val, inplace=True)\n",
    "            X_v[col].fillna(mode_val, inplace=True)\n",
    "            X_te[col].fillna(mode_val, inplace=True)\n",
    "            \n",
    "            if n_missing_train > 0 or n_missing_val > 0 or n_missing_test > 0:\n",
    "                print(f\"  {col} - mode: {mode_val}, imputed Train: {n_missing_train}, \"\n",
    "                      f\"Val: {n_missing_val}, Test: {n_missing_test}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 4: ENSURE KNOWN CATEGORICAL VALUES (before MICE)\n",
    "    # =========================================================================\n",
    "    print(\"\\n[4/6] SYNCHRONIZATION - force known categorical values\")\n",
    "    \n",
    "    cat_cols_to_sync = ['Brand', 'model', 'fuelType', 'transmission']\n",
    "    \n",
    "    for col in cat_cols_to_sync:\n",
    "        if col in X_tr.columns:\n",
    "            # Get known values (excluding NaN)\n",
    "            known_values = set(X_tr[col].dropna().unique())\n",
    "            mode_val = X_tr[col].mode()[0]\n",
    "            \n",
    "            # Val: replace unknown with mode (only non-null values)\n",
    "            mask_unknown_val = X_v[col].notna() & (~X_v[col].isin(known_values))\n",
    "            n_unknown_val = mask_unknown_val.sum()\n",
    "            if n_unknown_val > 0:\n",
    "                X_v.loc[mask_unknown_val, col] = mode_val\n",
    "                print(f\"  {col} - Val: {n_unknown_val} unknown values -> '{mode_val}'\")\n",
    "            \n",
    "            # Test: same\n",
    "            mask_unknown_test = X_te[col].notna() & (~X_te[col].isin(known_values))\n",
    "            n_unknown_test = mask_unknown_test.sum()\n",
    "            if n_unknown_test > 0:\n",
    "                X_te.loc[mask_unknown_test, col] = mode_val\n",
    "                print(f\"  {col} - Test: {n_unknown_test} unknown values -> '{mode_val}'\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 5: CORRELATED NUMERICAL - IterativeImputer (MICE)\n",
    "    # =========================================================================\n",
    "    print(\"\\n[5/6] NUMERICAL - IterativeImputer (MICE)\")\n",
    "    \n",
    "    numeric_cols = ['year', 'engineSize', 'mileage', 'mpg', 'tax', 'previousOwners']\n",
    "    if 'paintQuality%' in X_tr.columns:\n",
    "        numeric_cols.append('paintQuality%')\n",
    "    \n",
    "    # Check which have missing\n",
    "    numeric_cols_with_missing = [col for col in numeric_cols \n",
    "                                  if X_tr[col].isna().sum() > 0]\n",
    "    \n",
    "    if numeric_cols_with_missing:\n",
    "        print(f\"  Columns to impute: {numeric_cols_with_missing}\")\n",
    "        \n",
    "        # Prepare data for imputer\n",
    "        # Convert categorical to numeric codes temporarily\n",
    "        cat_cols = ['Brand', 'model', 'fuelType', 'transmission']\n",
    "        \n",
    "        # Create temporary copies\n",
    "        X_tr_temp = X_tr.copy()\n",
    "        X_v_temp = X_v.copy()\n",
    "        X_te_temp = X_te.copy()\n",
    "        \n",
    "        # Temporary label encoding\n",
    "        label_mappings = {}\n",
    "        for col in cat_cols:\n",
    "            if col in X_tr_temp.columns:\n",
    "                # Create mapping from train (excluding NaN)\n",
    "                unique_vals = X_tr_temp[col].dropna().unique()\n",
    "                mapping = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "                label_mappings[col] = mapping\n",
    "                \n",
    "                # Apply mapping (unknown values remain as NaN)\n",
    "                X_tr_temp[col] = X_tr_temp[col].map(mapping)\n",
    "                X_v_temp[col] = X_v_temp[col].map(mapping)\n",
    "                X_te_temp[col] = X_te_temp[col].map(mapping)\n",
    "        \n",
    "        # Select features for imputer\n",
    "        features_for_imputation = cat_cols + numeric_cols\n",
    "        features_for_imputation = [f for f in features_for_imputation if f in X_tr_temp.columns]\n",
    "        \n",
    "        # Configure and train imputer\n",
    "        imputer = IterativeImputer(\n",
    "            estimator=RandomForestRegressor(n_estimators=10, max_depth=10, random_state=42),\n",
    "            max_iter=10,\n",
    "            random_state=42,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Fit on train\n",
    "        X_tr_imputed = imputer.fit_transform(X_tr_temp[features_for_imputation])\n",
    "        X_v_imputed = imputer.transform(X_v_temp[features_for_imputation])\n",
    "        X_te_imputed = imputer.transform(X_te_temp[features_for_imputation])\n",
    "        \n",
    "        # Replace only imputed numerical columns\n",
    "        for i, col in enumerate(numeric_cols):\n",
    "            if col in features_for_imputation:\n",
    "                idx = features_for_imputation.index(col)\n",
    "                X_tr[col] = X_tr_imputed[:, idx]\n",
    "                X_v[col] = X_v_imputed[:, idx]\n",
    "                X_te[col] = X_te_imputed[:, idx]\n",
    "        \n",
    "        print(f\"  IterativeImputer applied successfully\")\n",
    "    else:\n",
    "        print(f\"  No numerical columns with missing values\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 6: VALIDATION AND CORRECTIONS\n",
    "    # =========================================================================\n",
    "    print(\"\\n[6/6] VALIDATION - checking logical limits\")\n",
    "    \n",
    "    # Sanity corrections\n",
    "    if 'year' in X_tr.columns:\n",
    "        for df in [X_tr, X_v, X_te]:\n",
    "            df['year'] = df['year'].clip(lower=1990, upper=2025)\n",
    "    \n",
    "    if 'engineSize' in X_tr.columns:\n",
    "        for df in [X_tr, X_v, X_te]:\n",
    "            df['engineSize'] = df['engineSize'].clip(lower=0.5, upper=10.0)\n",
    "    \n",
    "    if 'mileage' in X_tr.columns:\n",
    "        for df in [X_tr, X_v, X_te]:\n",
    "            df['mileage'] = df['mileage'].clip(lower=0, upper=500000)\n",
    "    \n",
    "    if 'mpg' in X_tr.columns:\n",
    "        for df in [X_tr, X_v, X_te]:\n",
    "            df['mpg'] = df['mpg'].clip(lower=10, upper=200)\n",
    "    \n",
    "    if 'tax' in X_tr.columns:\n",
    "        for df in [X_tr, X_v, X_te]:\n",
    "            df['tax'] = df['tax'].clip(lower=0, upper=1000)\n",
    "    \n",
    "    if 'previousOwners' in X_tr.columns:\n",
    "        for df in [X_tr, X_v, X_te]:\n",
    "            df['previousOwners'] = df['previousOwners'].clip(lower=0, upper=10).round()\n",
    "    \n",
    "    if 'paintQuality%' in X_tr.columns:\n",
    "        for df in [X_tr, X_v, X_te]:\n",
    "            df['paintQuality%'] = df['paintQuality%'].clip(lower=0, upper=100)\n",
    "    \n",
    "    print(f\"  Limits applied\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # FINAL REPORT\n",
    "    # =========================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"IMPUTATION COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nFinal missing values:\")\n",
    "    print(f\"  Train: {X_tr.isna().sum().sum()}\")\n",
    "    print(f\"  Val:   {X_v.isna().sum().sum()}\")\n",
    "    print(f\"  Test:  {X_te.isna().sum().sum()}\")\n",
    "    \n",
    "    if X_tr.isna().sum().sum() > 0:\n",
    "        print(\"\\nColumns with remaining NaNs in Train:\")\n",
    "        print(X_tr.isna().sum()[X_tr.isna().sum() > 0])\n",
    "    \n",
    "    if X_v.isna().sum().sum() > 0:\n",
    "        print(\"\\nColumns with remaining NaNs in Val:\")\n",
    "        print(X_v.isna().sum()[X_v.isna().sum() > 0])\n",
    "    \n",
    "    if X_te.isna().sum().sum() > 0:\n",
    "        print(\"\\nColumns with remaining NaNs in Test:\")\n",
    "        print(X_te.isna().sum()[X_te.isna().sum() > 0])\n",
    "    \n",
    "    if create_flags:\n",
    "        flag_cols = [col for col in X_tr.columns if col.endswith('_was_missing')]\n",
    "        print(f\"\\nFlags created: {len(flag_cols)} columns\")\n",
    "        if flag_cols:\n",
    "            print(f\"  Example: {flag_cols[:3]}\")\n",
    "    \n",
    "    return X_tr, X_v, X_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366274bf-19b3-488b-bceb-248f17dff76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestIndependence(X,y,var,alpha=0.05):        \n",
    "    dfObserved = pd.crosstab(y,X) \n",
    "    chi2, p, dof, expected = stats.chi2_contingency(dfObserved.values)\n",
    "    dfExpected = pd.DataFrame(expected, columns=dfObserved.columns, index = dfObserved.index)\n",
    "    if p<alpha:#if p<alpha we reject the null and there is a relationship so the var is important for prediction\n",
    "        result=\"{0} is IMPORTANT for Prediction\".format(var)#\n",
    "    else:\n",
    "        result=\"{0} is NOT an important predictor. (Discard {0} from model)\".format(var)#independent H0\n",
    "    print(result)\n",
    "\n",
    "for var in X_train_cat:\n",
    "    TestIndependence(X_train_cat[var],y_train, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe2d0a-fb40-441f-9c01-3177955ec70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_heatmap(cor):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(data = cor, annot = True, cmap = plt.cm.Purples, fmt='.1')\n",
    "    plt.show()\n",
    "cor_heatmap(cor_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8dd91-f560-46a6-8bce-4d2511ba4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_rfe(X, y, scoring='r2', cv=5, verbose=True):\n",
    "\n",
    "    model = LinearRegression()\n",
    "    n_features = X.shape[1]\n",
    "    scores = []\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Trying features\")\n",
    "\n",
    "    for n in range(1, n_features + 1):\n",
    "        rfe = RFE(model, n_features_to_select=n)\n",
    "        X_rfe = rfe.fit_transform(X, y)\n",
    "        score = np.mean(cross_val_score(model, X_rfe, y, scoring=scoring, cv=cv))\n",
    "        scores.append(score)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"{n:2d} features -> {scoring}: {score:.4f}\")\n",
    "\n",
    "    best_n = np.argmax(scores) + 1\n",
    "    best_score = scores[best_n - 1]\n",
    "\n",
    "    best_rfe = RFE(model, n_features_to_select=best_n)\n",
    "    best_rfe.fit(X, y)\n",
    "\n",
    "    feature_ranking = (\n",
    "        {feature: rank for feature, rank in zip(X.columns, best_rfe.ranking_)}\n",
    "        if hasattr(X, \"columns\")\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nBest number of features:\", best_n)\n",
    "        print(\"Best average score:\", round(best_score, 4))\n",
    "        if feature_ranking:\n",
    "            print(\"Selected features:\", X.columns[best_rfe.support_].tolist())\n",
    "\n",
    "    return best_rfe, best_n, best_score, feature_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe2bf9-3d35-49dc-be47-6348f8566551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(coef,name):\n",
    "    imp_coef = coef.sort_values()\n",
    "    plt.figure(figsize=(6,8))\n",
    "    imp_coef.plot(kind = \"barh\", color='purple')\n",
    "    plt.title(\"Feature importance using \" + name + \" Model\")\n",
    "    plt.show()\n",
    "plot_importance(coef,'Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce3791-aa13-4b41-9b3c-1b90339df6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_val, y_train, y_val):\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    print(\"Validation set:\")\n",
    "    print(\"R²:\", r2_score(y_val, y_pred_val))\n",
    "    print(\"MAE:\", mean_absolute_error(y_val, y_pred_val))\n",
    "    print(\"RMSE:\", root_mean_squared_error(y_val, y_pred_val))\n",
    "    print(\"\\nTraining set:\")\n",
    "    print(\"R²:\", r2_score(y_train, y_pred_train))\n",
    "    print(\"MAE:\", mean_absolute_error(y_train, y_pred_train))\n",
    "    print(\"RMSE:\", root_mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0f8a0-333c-4c61-9c47-0a6147cec288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_original_scale(model, X_train, X_val, y_train, y_val):\n",
    "    # predições em log\n",
    "    y_pred_train_log = model.predict(X_train)\n",
    "    y_pred_val_log = model.predict(X_val)\n",
    "\n",
    "    # voltar para a escala original\n",
    "    y_pred_train = np.exp(y_pred_train_log)\n",
    "    y_pred_val = np.exp(y_pred_val_log)\n",
    "\n",
    "    print(\"Validation set:\")\n",
    "    print(\"R²:\", r2_score(y_val, y_pred_val))\n",
    "    print(\"MAE:\", mean_absolute_error(y_val, y_pred_val))\n",
    "    print(\"RMSE:\", root_mean_squared_error(y_val, y_pred_val))\n",
    "    print(\"\\nTraining set:\")\n",
    "    print(\"R²:\", r2_score(y_train, y_pred_train))\n",
    "    print(\"MAE:\", mean_absolute_error(y_train, y_pred_train))\n",
    "    print(\"RMSE:\", root_mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"-\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
